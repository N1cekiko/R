```r
#install.packages('xml2')
library("xml2")
#install.packages("rvest")
library("rvest")
#install.packages("dplyr")
library("dplyr")
#install.packages("stringr")
library("stringr")
#install.packages("httr")
library("httr")
```

rvest的核心函数

read_html():下载并解析网页
html_nodes():定位并获取节点信息
html_text():提取节点属性文本信息

XPath:
nodename:选择该节点的所有子节点
“/”:选择根节点
“//”:选择任意节点
“@”：选择属性

```r
read_html('https://movie.douban.com/subject/26862829/')%>% html_nodes(xpath='*//h1//span')
```

SelectorGadget快速定位节点信息的插件。  

#对爬取页数进行设定并创建数据框。
i=1:100
house_inf=data.frame()
#利用for循环封装爬虫代码，进行批量抓取。
for (i in 1:100){
  #发现url规律，利用字符串函数进行url拼接并规定编码
  web=read_html(str_c('http://hz.lianjia.com/ershoufang/pg',i),encoding='UTF-8')
  #提取房名信息
  house_name=web %>% html_nodes('.houseInfo a') %>% html_text
  #提取房名基本信息并消除空格
  house_basic_inf=web %>% html_nodes('.houseInfo') %>% html_text
  house_basic_inf=str_replace_all(house_basic_inf,' ',' ')
  #提取二手房地址信息
  house_adress= web %>% html_nodes('.positionInfo a') %>% html_text
  #提取二手房总价信息
  house_totalprice=web %>% html_nodes('.totalPrice') %>% html_text
  #提取二手房单价信息
  house_unitprice=web  %>% html_nodes('.unitPrice span') %>% html_text
  #提取跟踪信息
  house_followInfo=web %>% html_nodes('.followInfo') %>% html_text
  #创建数据框存储以上信息
  house=data.frame(house_name,house_basic_inf,house_adress,house_totalprice,house_unitprice,house_followInfo)
  house_inf=rbind(house_inf,house)
}

#把数据写入CSV文档
write.csv(house_inf,file='./house_inf.csv')
a=read.csv('house_inf.csv')
